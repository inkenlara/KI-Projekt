{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split data\n",
    "\n",
    "import pickle\n",
    "from graph import Graph, Part\n",
    "from typing import List, Set, Tuple, Dict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(\"data/graphs.dat\", \"rb\") as file:\n",
    "    all_graphs: List[Graph] = pickle.load(file)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        list(map(lambda g: g.get_parts(), all_graphs)),\n",
    "        all_graphs,\n",
    "        test_size=0.3,\n",
    "        random_state=0,\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model and store results (in-)correct train/validation graphs\n",
    "\n",
    "from model import InstanceBased\n",
    "\n",
    "ib = InstanceBased(y_train, edge_pickle_store=True)\n",
    "print(f\"Order Validation: {ib.evaluate_order(y_val) / len(y_val)}% accuracy\\n\")\n",
    "\n",
    "y_train_prev_right = []\n",
    "y_train_prev_wrong = []\n",
    "y_val_prev_right = []\n",
    "y_val_prev_wrong = []\n",
    "\n",
    "correct_train = 0\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] == ib.createGraph(X_train[i]):\n",
    "        correct_train += 1\n",
    "        y_train_prev_right.append(y_train[i])\n",
    "    else:\n",
    "        y_train_prev_wrong.append(y_train[i])\n",
    "print(f\"train_err: {correct_train / len(y_train)}\")\n",
    "correct_val = 0\n",
    "for i in range(len(y_val)):\n",
    "    if y_val[i] == ib.createGraph(X_val[i]):\n",
    "        correct_val += 1\n",
    "        y_val_prev_right.append(y_val[i])\n",
    "    else:\n",
    "        y_val_prev_wrong.append(y_val[i])\n",
    "print(f\"val_err: {correct_val / len(y_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and store it for evaluation.py\n",
    "# Calculate graph accuracy for training, validation, and test set\n",
    "\n",
    "ib = InstanceBased(y_train, edge_pickle_load=True)\n",
    "with open(f\"data/model.dat\", \"wb\") as file:\n",
    "    pickle.dump(ib, file)\n",
    "\n",
    "def checkAccuracy(name, graphs):\n",
    "    correct_count = 0\n",
    "    for i in range(len(graphs)):\n",
    "        if graphs[i] == ib.createGraph(graphs[i].get_parts()):\n",
    "            correct_count += 1\n",
    "    print(f\"{name}: {100 * correct_count / len(graphs)}%\")\n",
    "\n",
    "print()\n",
    "checkAccuracy(\"Training Set\", y_train)\n",
    "checkAccuracy(\"Validation Set\", y_val)\n",
    "checkAccuracy(\"Test Set\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Edge Accuracy for validation and test set\n",
    "\n",
    "from itertools import permutations\n",
    "import numpy as np\n",
    "\n",
    "def evaluate( data_set: List[Tuple[Set[Part], Graph]]) -> float:\n",
    "    \"\"\"\n",
    "    Evaluates a given prediction model on a given data set.\n",
    "    :param model: prediction model\n",
    "    :param data_set: data set\n",
    "    :return: evaluation score (for now, edge accuracy in percent)\n",
    "    \"\"\"\n",
    "    sum_correct_edges = 0\n",
    "    edges_counter = 0\n",
    "\n",
    "    for input_parts, target_graph in data_set:\n",
    "        predicted_graph = ib.createGraph(input_parts)\n",
    "\n",
    "        edges_counter += len(input_parts) * len(input_parts)\n",
    "        sum_correct_edges += edge_accuracy(predicted_graph, target_graph)\n",
    "\n",
    "    return sum_correct_edges / edges_counter * 100\n",
    "\n",
    "\n",
    "def edge_accuracy(predicted_graph: Graph, target_graph: Graph) -> int:\n",
    "    \"\"\"\n",
    "    Returns the number of correct predicted edges.\n",
    "    :param predicted_graph:\n",
    "    :param target_graph:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert len(predicted_graph.get_nodes()) == len(target_graph.get_nodes()), 'Mismatch in number of nodes.'\n",
    "    assert predicted_graph.get_parts() == target_graph.get_parts(), 'Mismatch in expected and given parts.'\n",
    "\n",
    "    best_score = 0\n",
    "\n",
    "    # Determine all permutations for the predicted graph and choose the best one in evaluation\n",
    "    perms: List[Tuple[Part]] = __generate_part_list_permutations(predicted_graph.get_parts())\n",
    "\n",
    "    # Determine one part order for the target graph\n",
    "    target_parts_order = perms[0]\n",
    "    target_adj_matrix = target_graph.get_adjacency_matrix(target_parts_order)\n",
    "\n",
    "    for perm in perms:\n",
    "        predicted_adj_matrix = predicted_graph.get_adjacency_matrix(perm)\n",
    "        score = np.sum(predicted_adj_matrix == target_adj_matrix)\n",
    "        best_score = max(best_score, score)\n",
    "\n",
    "    return best_score\n",
    "\n",
    "\n",
    "def __generate_part_list_permutations(parts: Set[Part]) -> List[Tuple[Part]]:\n",
    "    \"\"\"\n",
    "    Different instances of the same part type may be interchanged in the graph. This method computes all permutations\n",
    "    of parts while taking this into account. This reduced the number of permutations.\n",
    "    :param parts: Set of parts to compute permutations\n",
    "    :return: List of part permutations\n",
    "    \"\"\"\n",
    "    # split parts into sets of same part type\n",
    "    equal_parts_sets: Dict[Part, Set[Part]] = {}\n",
    "    for part in parts:\n",
    "        for seen_part in equal_parts_sets.keys():\n",
    "            if part.equivalent(seen_part):\n",
    "                equal_parts_sets[seen_part].add(part)\n",
    "                break\n",
    "        else:\n",
    "            equal_parts_sets[part] = {part}\n",
    "\n",
    "    multi_occurrence_parts: List[Set[Part]] = [pset for pset in equal_parts_sets.values() if len(pset) > 1]\n",
    "    single_occurrence_parts: List[Part] = [next(iter(pset)) for pset in equal_parts_sets.values() if len(pset) == 1]\n",
    "\n",
    "    full_perms: List[Tuple[Part]] = [()]\n",
    "    for mo_parts in multi_occurrence_parts:\n",
    "        perms = list(permutations(mo_parts))\n",
    "        full_perms = list(perms) if full_perms == [()] else [t1 + t2 for t1 in full_perms for t2 in perms]\n",
    "\n",
    "    # Add single occurrence parts\n",
    "    full_perms = [fp + tuple(single_occurrence_parts) for fp in full_perms]\n",
    "    assert all([len(perm) == len(parts) for perm in full_perms]), 'Mismatching number of elements in permutation(s).'\n",
    "    return full_perms\n",
    "\n",
    "print(evaluate(list(zip(X_val, y_val))))\n",
    "print(evaluate(list(zip(X_test, y_test))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
